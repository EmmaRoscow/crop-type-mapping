{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import warnings\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "# Set path so that functions can be imported from the utils script\n",
    "sys.path.insert(0, '../')\n",
    "from preprocess import sample_timeseries\n",
    "from visualize import visualize_rgb, record_batch\n",
    "from constants import *\n",
    "import datasets\n",
    "import util\n",
    "import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_models = ['data_loader', 'crnn'] #, 'fcn_crnn', cnn', nn', 'rf', 'lr']\n",
    "\n",
    "# For 'lr', 'rf', 'cnn', 'nn', normalize=False\n",
    "# For fcn_crnn, clstm, normalize=True\n",
    "normalize = True\n",
    "\n",
    "train_parser = util.get_train_parser()\n",
    "args = train_parser.parse_args(['--model_name', 'bidir_clstm', #fcn_crnn\n",
    "                                '--dataset', 'full', \n",
    "                                '--country', 'ghana',\n",
    "                                '--batch_size', str(5),\n",
    "                                '--hidden_dims', str(64), #32\n",
    "                                '--crnn_num_layers', str(1),\n",
    "                                '--use_s1', str(False),\n",
    "                                '--use_s2', str(True),\n",
    "                                '--sample_w_clouds', str(True),\n",
    "                                '--include_clouds', str(True),\n",
    "                                '--include_doy', str(True),\n",
    "                                '--bidirectional', str(False), #True\n",
    "                                '--shuffle', str(False),\n",
    "                                '--normalize', str(normalize),\n",
    "                                '--apply_transforms', str(False),\n",
    "                                '--least_cloudy', str(True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fcn_crnn_model_path = '/home/data/ghana/models/best_from_scratch_fcn_crnn'\n",
    "#fcn_crnn_model_path = '/home/data/ghana/models/best_pretrained_fcn_crnn'\n",
    "crnn_model_path = '/home/data/ghana/models/best_bidir_clstm'\n",
    "\n",
    "dates = None\n",
    "batch = args.batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = datasets.get_dataloaders('ghana', 'full', args=args)\n",
    "dl = dataloaders['test']\n",
    "split = 'test'\n",
    "vis_data = None\n",
    "vis = None\n",
    "\n",
    "if 'cnn' in show_models:\n",
    "    model_json = '/home/data/ghana/models/best_1dcnn_model.json'\n",
    "    model_hdf5 = '/home/data/ghana/models/best_1dcnn_model.hdf5'\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(model_json, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model_cnn = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model_cnn.load_weights(model_hdf5)\n",
    "    print(\"Loaded model from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    loaded_model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "if 'nn' in show_models:\n",
    "    model_json = '/home/data/ghana/models/best_1dnn_model.json'\n",
    "    model_hdf5 = '/home/data/ghana/models/best_1dnn_model.hdf5'\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(model_json, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model_nn = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model_nn.load_weights(model_hdf5)\n",
    "    print(\"Loaded model from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    loaded_model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "if 'rf' in show_models:\n",
    "    filename = '/home/data/ghana/models/random_forest_model'\n",
    "    loaded_model_rf = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "if 'lr' in show_models:\n",
    "    filename = '/home/data/ghana/models/logistic_regression_model'\n",
    "    loaded_model_lr = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "if 'cnn' in show_models or 'nn' in show_models:\n",
    "    X_train = np.load('/home/data/ghana/pixel_arrays/full/raw/full_raw_s2_cloud_mask_reverseFalse_bytime_Xtrain_g2260.npy')\n",
    "    # Normalize by standard scalar\n",
    "    scaler = StandardScaler()\n",
    "    print(X_train.shape)\n",
    "    scaler.fit(X_train)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_channels(array, num_bands=11):\n",
    "    bs = []\n",
    "    for b in range(num_bands):\n",
    "        bs.append(array[:, b::num_bands])\n",
    "    return np.dstack(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'data_loader' in show_models:\n",
    "    model_name = 'fcn_crnn'\n",
    "    if 'fcn_crnn' in show_models:\n",
    "        fcn_crnn_model = models.get_model(**vars(args))\n",
    "        fcn_crnn_model.load_state_dict(torch.load(fcn_crnn_model_path))\n",
    "        fcn_crnn_model.eval()\n",
    "        \n",
    "    if 'crnn' in show_models:\n",
    "        model_name = 'bidir_clstm'\n",
    "        crnn_model = models.get_model(**vars(args))\n",
    "        crnn_model.load_state_dict(torch.load(crnn_model_path))\n",
    "        crnn_model.eval()\n",
    "        crnn_model.to(device=args.device)\n",
    "  \n",
    "    count = 0\n",
    "    for inputs, targets, cloudmasks in dl:\n",
    "        if 'fcn_crnn' in show_models:\n",
    "            preds = fcn_crnn_model(inputs)\n",
    "        elif 'crnn' in show_models:\n",
    "            preds = crnn_model(inputs)\n",
    "        else:\n",
    "            preds = torch.zeros(5, 4, 64, 64)\n",
    "            # preds torch.Size([5, 4, 64, 64])\n",
    "        labels_grid, inputs_grid, targets_grid, preds_grid, predsmask_grid = record_batch(\n",
    "                                                                           inputs, cloudmasks, targets, preds, #<< preds\n",
    "                                                                           NUM_CLASSES[args.country], split, vis_data, \n",
    "                                                                           vis, args.include_doy, args.use_s1, \n",
    "                                                                           args.use_s2, model_name, args.time_slice, \n",
    "                                                                           save=False, save_dir=None, \n",
    "                                                                           show_visdom=False, show_matplot=True)\n",
    "        \n",
    "        #plt.figure(figsize=(10,10))\n",
    "        #plt.imshow(np.transpose(labels_grid, (1, 2, 0)))\n",
    "        #plt.title('labels')\n",
    "        #plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(inputs_grid, (1, 2, 0)))\n",
    "        plt.title('inputs: {}'.format(count))\n",
    "        plt.show()\n",
    "    \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(targets_grid, (1, 2, 0)))\n",
    "        plt.title('targets: {}'.format(count))\n",
    "        plt.show()\n",
    "        \n",
    "        if model_name == 'fcn_crnn':\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(np.transpose(preds_grid, (1, 2, 0)))\n",
    "            plt.title('FCN CRNN predictions: {}'.format(count))\n",
    "            plt.show()\n",
    "        \n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(np.transpose(predsmask_grid, (1, 2, 0)))\n",
    "            plt.title('FCN CRNN predictions with mask: {}'.format(count))\n",
    "            plt.show()\n",
    "            \n",
    "        elif model_name == 'bidir_clstm':\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(np.transpose(preds_grid, (1, 2, 0)))\n",
    "            plt.title('CRNN predictions: {}'.format(count))\n",
    "            plt.show()\n",
    "        \n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(np.transpose(predsmask_grid, (1, 2, 0)))\n",
    "            plt.title('CRNN predictions with mask: {}'.format(count))\n",
    "            plt.show()\n",
    "        \n",
    "        if 'cnn' in show_models or 'nn' in show_models or 'rf' in show_models or 'lr' in show_models:\n",
    "            b, t, c, h, w = inputs.shape\n",
    "            data = np.transpose(inputs, (0, 3, 4, 1, 2))\n",
    "            data = data[:, :, :, :, :11]\n",
    "            #data = np.reshape(data, (b, -1, t*(c-1)))\n",
    "            \n",
    "            cur_batch_imgs_cnn = []\n",
    "            cur_batch_imgs_nn = []\n",
    "            cur_batch_imgs_rf = []\n",
    "            cur_batch_imgs_lr = []\n",
    "            \n",
    "            for curb in range(b):\n",
    "                \n",
    "                if 'cnn' in show_models:\n",
    "                    data_in = data[curb,:, :, :, :] #\n",
    "                    data_cnn = np.transpose(data_in, (3, 0, 1, 2))#\n",
    "                    data_cnn = np.reshape(data_cnn, (c-1, h*w, t)) #\n",
    "                    data_cnn = np.swapaxes(data_cnn, 0, 1) #\n",
    "                    data_cnn = np.swapaxes(data_cnn, 1, 2).reshape(data_cnn.shape[0], -1)\n",
    "                    \n",
    "                    data_cnn = scaler.transform(data_cnn)\n",
    "                    data_cnn = reshape_channels(data_cnn)      \n",
    "                    \n",
    "                    #data_in = np.reshape(data, (b, -1, t*(c-1)))\n",
    "                    #data_in = scaler.transform(data_in[curb,:, :])\n",
    "                    #data_cnn = np.reshape(data_in, (64*64, -1, 11))     \n",
    "                    pred_cnn = np.argmax(loaded_model_cnn.predict(data_cnn), axis=1) + 1\n",
    "                    pred_cnn = np.reshape(pred_cnn, (1, 1, 64, 64))\n",
    "                    pred_cnn = visualize_rgb(pred_cnn, num_classes=NUM_CLASSES[args.country])\n",
    "                    cur_batch_imgs_cnn.append(pred_cnn)\n",
    "                \n",
    "                if 'nn' in show_models:\n",
    "                    data_in = data[curb,:, :, :, :] #\n",
    "                    data_nn = np.transpose(data_in, (3, 0, 1, 2))#\n",
    "                    data_nn = np.reshape(data_nn, (c-1, h*w, t)) #\n",
    "                    data_nn = np.swapaxes(data_nn, 0, 1) #\n",
    "                    data_nn = np.swapaxes(data_nn, 1, 2).reshape(data_nn.shape[0], -1)\n",
    "                    \n",
    "                    data_nn = scaler.transform(data_nn)\n",
    "                    data_nn = reshape_channels(data_nn)\n",
    "                    \n",
    "                    #data_in = np.reshape(data, (b, -1, t*(c-1)))\n",
    "                    #data_in = scaler.transform(data_in[curb,:, :])\n",
    "                    #data_nn = np.reshape(data_in, (64*64, -1, 11))     \n",
    "                    pred_nn = np.argmax(loaded_model_nn.predict(data_nn), axis=1) + 1\n",
    "                    pred_nn = np.reshape(pred_nn, (1, 1, 64, 64))\n",
    "                    pred_nn = visualize_rgb(pred_nn, num_classes=NUM_CLASSES[args.country])\n",
    "                    cur_batch_imgs_nn.append(pred_nn)\n",
    "                    \n",
    "                if 'rf' in show_models:\n",
    "                    data_in = data[curb,:, :, :, :] #\n",
    "                    data_rf = np.transpose(data_in, (3, 0, 1, 2))#\n",
    "                    data_rf = np.reshape(data_rf, (c-1, h*w, t)) #\n",
    "                    data_rf = np.swapaxes(data_rf, 0, 1) #\n",
    "                    data_rf = np.swapaxes(data_rf, 1, 2).reshape(data_rf.shape[0], -1) #\n",
    "                    \n",
    "                    #data_rf = np.reshape(data_in, (64*64, -1, 11)) \n",
    "                    #data_rf = np.transpose(data_rf, (0, 2, 1))\n",
    "                    #data_rf = np.reshape(data_rf, (64*64, -1))  \n",
    "                    print('data rf: ', data_rf.shape)\n",
    "                    pred_rf = loaded_model_rf.predict(data_rf)\n",
    "                    pred_rf = np.reshape(pred_rf, (1, 1, 64, 64))\n",
    "                    pred_rf = visualize_rgb(pred_rf, num_classes=NUM_CLASSES[args.country])\n",
    "                    cur_batch_imgs_rf.append(pred_rf)\n",
    "\n",
    "                if 'lr' in show_models:\n",
    "                    data_in = data[curb,:, :, :, :] #\n",
    "                    data_lr = np.transpose(data_in, (3, 0, 1, 2))#\n",
    "                    data_lr = np.reshape(data_lr, (c-1, h*w, t)) #\n",
    "                    data_lr = np.swapaxes(data_lr, 0, 1) #\n",
    "                    data_lr = np.swapaxes(data_lr, 1, 2).reshape(data_lr.shape[0], -1) #\n",
    "                    #data_in = data[curb,:, :]\n",
    "                    #data_lr = np.reshape(data_in, (64*64, -1, 11)) \n",
    "                    #data_lr = np.transpose(data_lr, (0, 2, 1))\n",
    "                    #data_lr = np.reshape(data_lr, (64*64, -1))  \n",
    "                    pred_lr = loaded_model_lr.predict(data_lr)\n",
    "                    pred_lr = np.reshape(pred_lr, (1, 1, 64, 64))\n",
    "                    pred_lr = visualize_rgb(pred_lr, num_classes=NUM_CLASSES[args.country])                        \n",
    "                    cur_batch_imgs_lr.append(pred_lr)\n",
    "            \n",
    "            if 'cnn' in show_models:\n",
    "                cur_batch_imgs_cnn = np.concatenate(cur_batch_imgs_cnn, axis=0)\n",
    "                cur_batch_grid_cnn = make_grid(torch.from_numpy(cur_batch_imgs_cnn), nrow=8, padding=8, normalize=False, range=None, scale_each=False, pad_value=255)\n",
    "                cur_batch_grid_cnn = np.transpose(cur_batch_grid_cnn, (1, 2, 0))\n",
    "    \n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_cnn)\n",
    "                plt.title('1D CNN predictions: {}'.format(count))\n",
    "                plt.show() \n",
    "\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_cnn * np.transpose(labels_grid, (1, 2, 0)).type(torch.DoubleTensor))\n",
    "                plt.title('1D CNN predictions masked: {}'.format(count))\n",
    "                plt.show()\n",
    "\n",
    "            if 'nn' in show_models:\n",
    "                cur_batch_imgs_nn = np.concatenate(cur_batch_imgs_nn, axis=0)\n",
    "                cur_batch_grid_nn = make_grid(torch.from_numpy(cur_batch_imgs_nn), nrow=8, padding=8, normalize=False, range=None, scale_each=False, pad_value=255)\n",
    "                cur_batch_grid_nn = np.transpose(cur_batch_grid_nn, (1, 2, 0))\n",
    "    \n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_nn)\n",
    "                plt.title('1D NN predictions: {}'.format(count))\n",
    "                plt.show() \n",
    "\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_nn * np.transpose(labels_grid, (1, 2, 0)).type(torch.DoubleTensor))\n",
    "                plt.title('1D NN predictions masked: {}'.format(count))\n",
    "                plt.show()\n",
    "                \n",
    "            if 'rf' in show_models:\n",
    "                \n",
    "                cur_batch_imgs_rf = np.concatenate(cur_batch_imgs_rf, axis=0)\n",
    "                cur_batch_grid_rf = make_grid(torch.from_numpy(cur_batch_imgs_rf), nrow=8, padding=8, normalize=False, range=None, scale_each=False, pad_value=255)\n",
    "                cur_batch_grid_rf = np.transpose(cur_batch_grid_rf, (1, 2, 0))\n",
    "    \n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_rf)\n",
    "                plt.title('Random Forest predictions: {}'.format(count))\n",
    "                plt.show() \n",
    "\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_rf * np.transpose(labels_grid, (1, 2, 0)).type(torch.DoubleTensor))\n",
    "                plt.title('Random Forest predictions masked: {}'.format(count))\n",
    "                plt.show()\n",
    "            \n",
    "            if 'lr' in show_models:\n",
    "                    \n",
    "                cur_batch_imgs_lr = np.concatenate(cur_batch_imgs_lr, axis=0)\n",
    "                cur_batch_grid_lr = make_grid(torch.from_numpy(cur_batch_imgs_lr), nrow=8, padding=8, normalize=False, range=None, scale_each=False, pad_value=255)\n",
    "                cur_batch_grid_lr = np.transpose(cur_batch_grid_lr, (1, 2, 0))\n",
    "                    \n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_lr)\n",
    "                plt.title('Multiclass Logistic Regression predictions: {}'.format(count))\n",
    "                plt.show() \n",
    "\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(cur_batch_grid_lr * np.transpose(labels_grid, (1, 2, 0)).type(torch.DoubleTensor))\n",
    "                plt.title('Multiclass Logistic Regression predictions masked: {}'.format(count))\n",
    "                plt.show()\n",
    "                \n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
