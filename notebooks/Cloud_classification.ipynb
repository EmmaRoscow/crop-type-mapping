{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud classification using pixel type labels from FSE\n",
    "\n",
    "### Classes:\n",
    "- clear, 0\n",
    "- cloud, 1\n",
    "- haze, 2\n",
    "- shadow, 3\n",
    "\n",
    "53,498 total point samples were collected across the ten Sentinel-2 bands without any scaling applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# This should be '/home/croptype/bin/python'\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "\n",
    "import pylab as pl\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/data/clouds/'\n",
    "data_fname = 'clean_samples.csv'\n",
    "\n",
    "data_path = os.path.join(data_dir, data_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df_sub = df[['poly_id', 'pixel_id', 'class', 'blue', 'green', 'red', 'rded1', \n",
    "             'rded2', 'rded3', 'nir', 'rded4', 'swir1', 'swir2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column class_num that takes the class and gives it a categorial representation\n",
    "# clear -> 0, cloud -> 1, haze -> 2, shadow -> 3\n",
    "df_sub['class'] = pd.Categorical(df_sub['class'])\n",
    "df_sub['class_num'] = df_sub['class'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data according to poly_ID, which contain 5 pixels each\n",
    "X = df_sub\n",
    "groups = df_sub['poly_id']\n",
    "\n",
    "train_inds, test_inds = next(GroupShuffleSplit(n_splits=3, test_size=0.1, train_size=0.8).split(X, groups=groups))\n",
    "\n",
    "val_inds = []\n",
    "for i in range(X.shape[0]):\n",
    "    if i not in train_inds and i not in test_inds:\n",
    "        val_inds.append(i)\n",
    "        \n",
    "val_inds = np.asarray(val_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset by shuffling train, val, and test indices\n",
    "np.random.seed(1234)\n",
    "\n",
    "np.random.shuffle(train_inds)\n",
    "np.random.shuffle(val_inds)\n",
    "np.random.shuffle(test_inds)\n",
    "\n",
    "# Check if shuffled\n",
    "print(train_inds)\n",
    "print(val_inds)\n",
    "print(test_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X.values[train_inds,3:-1], X.values[train_inds,-1].astype(int)\n",
    "X_val, y_val = X.values[val_inds, 3:-1], X.values[val_inds, -1].astype(int)\n",
    "X_test, y_test = X.values[test_inds, 3:-1], X.values[test_inds, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest classifier\n",
    "# n_estimators - more trees, less likely to overfit?\n",
    "# max_features - the smaller, the less likely to overfit\n",
    "# max_depth - reduce to reduce complexity \n",
    "# min_samples_leaf - set > 1?\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1, n_estimators=50)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from the model\n",
    "train_pred_lbls = model.predict(X_train)\n",
    "val_pred_lbls = model.predict(X_val)\n",
    "test_pred_lbls = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished classifying. Get the accuracy scores and f1-scores\n",
    "tr_score = model.score(X_train, y_train)\n",
    "val_score = model.score(X_val, y_val)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print('train scores: ', tr_score)\n",
    "print('val scores: ', val_score)\n",
    "print('test scores: {}\\n'.format(test_score))\n",
    "\n",
    "tr_f1 = f1_score(y_train, train_pred_lbls, average='micro')\n",
    "val_f1 = f1_score(y_val, val_pred_lbls, average='micro')\n",
    "test_f1 = f1_score(y_test, test_pred_lbls, average='micro')\n",
    "\n",
    "print('train f-1 score: ', tr_f1)\n",
    "print('val f-1 score: ', val_f1)\n",
    "print('test f-1 score: ', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "train_kappa = cohen_kappa_score(y_train, train_pred_lbls)\n",
    "train_cm = confusion_matrix(y_train, train_pred_lbls)\n",
    "\n",
    "val_kappa = cohen_kappa_score(y_val, val_pred_lbls)\n",
    "val_cm = confusion_matrix(y_val, val_pred_lbls)\n",
    "\n",
    "test_kappa = cohen_kappa_score(y_test, test_pred_lbls)\n",
    "test_cm = confusion_matrix(y_test, test_pred_lbls)\n",
    "\n",
    "print('Train kappa: ', train_kappa)\n",
    "print('Validation kappa: ', val_kappa)\n",
    "print('Test kappa: ', test_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['clear', 'cloud', 'haze', 'shadow']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(train_cm, classes=class_names,\n",
    "                      title='Training confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(train_cm, classes=class_names, normalize=True,\n",
    "                      title='Normalized training confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(val_cm, classes=class_names,\n",
    "                      title='Validation confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(val_cm, classes=class_names, normalize=True,\n",
    "                      title='Normalized validation confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(test_cm, classes=class_names,\n",
    "                      title='Test confusion matrix, without normalization')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(test_cm, classes=class_names, normalize=True,\n",
    "                      title='Normalized test confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2_format(s2):\n",
    "    s2_bgr = s2[0:3, :, :]\n",
    "    s2_bgr = np.transpose(s2_bgr, (1, 2, 0))\n",
    "\n",
    "    s2_rgb = np.zeros_like(s2_bgr)\n",
    "    s2_rgb[:,:,0] = s2_bgr[:,:,2]\n",
    "    s2_rgb[:,:,1] = s2_bgr[:,:,1]\n",
    "    s2_rgb[:,:,2] = s2_bgr[:,:,0]\n",
    "    \n",
    "    # normalize using bounds from QGIS\n",
    "    minval = 1100\n",
    "    maxval = 2100\n",
    "\n",
    "    s2_rgb[:,:,0] = (s2_rgb[:,:,0] - minval) / (maxval - minval)\n",
    "    s2_rgb[:,:,1] = (s2_rgb[:,:,1] - minval) / (maxval - minval)\n",
    "    s2_rgb[:,:,2] = (s2_rgb[:,:,2] - minval) / (maxval - minval)  \n",
    "    return s2_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_legend():\n",
    "    plt.figure()\n",
    "    plt.subplot(141)\n",
    "    plt.title('clear')\n",
    "    plt.imshow(np.zeros((10,10)), vmin=0, vmax=3)\n",
    "    plt.subplot(142)\n",
    "    plt.title('cloud')\n",
    "    plt.imshow(np.ones((10,10)), vmin=0, vmax=3)\n",
    "    plt.subplot(143)\n",
    "    plt.title('haze')\n",
    "    plt.imshow(np.ones((10,10))*2, vmin=0, vmax=3)\n",
    "    plt.subplot(144)\n",
    "    plt.title('shadow')\n",
    "    plt.imshow(np.ones((10,10))*3, vmin=0, vmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(img_array):\n",
    "    for i in range(img_array.shape[0]):\n",
    "        pl.imshow(img_array[i])\n",
    "        pl.title('Time Number: ' + str(i))\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some images and create cloud masks \n",
    "#data_dir = '/home/data/small/val/s2'\n",
    "data_dir = '/home/data/Ghana/s2_64x64_npy/'\n",
    "data_fnames = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if fname.endswith('.npy')]\n",
    "\n",
    "mask_dir = os.path.join(data_dir, 'cloud_masks')\n",
    "if not os.path.exists(mask_dir):\n",
    "    os.mkdir(mask_dir)\n",
    "\n",
    "for fname in data_fnames:\n",
    "    arr = np.load(fname)\n",
    "    mask_arr = np.zeros((arr.shape[1], arr.shape[2], arr.shape[3]))\n",
    "    \n",
    "    for timestamp in range(arr.shape[3]):\n",
    "        cur_img = arr[:,:,:,timestamp]\n",
    "        disp_img = s2_format(cur_img)\n",
    "        cur_img = np.transpose(cur_img, (1, 2, 0))\n",
    "        cur_img = np.reshape(cur_img, [-1, 10])\n",
    "        cur_pred = model.predict(cur_img)\n",
    "        cur_pred = np.reshape(cur_pred, (64, 64))\n",
    "        \n",
    "        mask_arr[:,:,timestamp] = cur_pred\n",
    "        \n",
    "        ##plt.figure()\n",
    "        #plt.subplot(121)\n",
    "        #plt.imshow(cur_pred, vmin=0, vmax=3)\n",
    "        #plt.subplot(122)\n",
    "        #plt.imshow(disp_img)\n",
    "        ##plt.show()\n",
    "        \n",
    "        #display.clear_output(wait=True)\n",
    "        #display.display(pl.gcf())\n",
    "        #time.sleep(0.5)\n",
    "    \n",
    "    out_fname = os.path.join(mask_dir, fname.split('/')[-1].split('.')[0]+'_mask.npy')\n",
    "    #print(\"Mask for {} saved to {}\".format(fname, out_fname))\n",
    "    np.save(out_fname, mask_arr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
